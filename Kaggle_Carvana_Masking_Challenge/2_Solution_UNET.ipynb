{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.5"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data.dataset import Dataset as Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable \n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import PIL\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../DeepLearningDataset/Kaggle_Carvana_Masking_Challenge/dataset'\n",
    "\n",
    "TRAIN_DATA_PATH = glob('/'.join([DATA_PATH,'train/*.jpg']))\n",
    "TRAIN_MASKS_PATH = glob('/'.join([DATA_PATH,'train_masks/*.gif']))\n",
    "TEST_PATH = glob('/'.join([DATA_PATH,'test/*.jpg']))\n",
    "\n",
    "TRANSFORM = transforms.Compose([transforms.ToTensor()])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "../DeepLearningDataset/Kaggle_Carvana_Masking_Challenge/dataset/train_masks/16f0ec26d608_03_mask.gif\n../DeepLearningDataset/Kaggle_Carvana_Masking_Challenge/dataset/train/bd8d5780ed04_07.jpg\n"
    }
   ],
   "source": [
    "print(TRAIN_MASKS_PATH[0])\n",
    "print(TRAIN_DATA_PATH[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "5088"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TRAIN_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_PATH.sort()\n",
    "TRAIN_MASKS_PATH.sort()\n",
    "TEST_PATH.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CarvanaDataset(Dataset):\n",
    "    def __init__(self,train_path,masks_path):\n",
    "        self.train_path = train_path \n",
    "        self.masks_path = masks_path\n",
    "\n",
    "    def transforms(self,image,mask):\n",
    "        image = image.resize((64, 64), PIL.Image.NEAREST)\n",
    "        mask = mask.resize((64, 64), PIL.Image.NEAREST)\n",
    "        image = TF.to_tensor(image)\n",
    "        mask = TF.to_tensor(mask)\n",
    "        return(image,mask)\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        image = Image.open(self.train_path[index])\n",
    "        mask  = Image.open(self.masks_path[index])\n",
    "\n",
    "        x,y = self.transforms(image,mask)\n",
    "        return(x,y)\n",
    "   \n",
    "    def __len__(self):\n",
    "        return(len(self.train_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_Dataset  = CarvanaDataset(TRAIN_DATA_PATH,TRAIN_MASKS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "tensor([[[0.9490, 0.9490, 0.9412,  ..., 0.9490, 0.9490, 0.9569],\n         [0.9490, 0.9490, 0.9490,  ..., 0.9490, 0.9412, 0.9490],\n         [0.9490, 0.9490, 0.9490,  ..., 0.9490, 0.9490, 0.9490],\n         ...,\n         [0.6902, 0.6824, 0.6588,  ..., 0.4510, 0.6941, 0.7020],\n         [0.6863, 0.6902, 0.6902,  ..., 0.6745, 0.6824, 0.6902],\n         [0.6980, 0.6902, 0.6824,  ..., 0.6745, 0.6745, 0.6902]],\n\n        [[0.9529, 0.9490, 0.9412,  ..., 0.9490, 0.9490, 0.9569],\n         [0.9529, 0.9490, 0.9490,  ..., 0.9490, 0.9412, 0.9490],\n         [0.9490, 0.9490, 0.9490,  ..., 0.9490, 0.9490, 0.9490],\n         ...,\n         [0.7059, 0.6980, 0.6980,  ..., 0.4039, 0.6980, 0.7020],\n         [0.7020, 0.7059, 0.7059,  ..., 0.6902, 0.6980, 0.7059],\n         [0.7137, 0.7059, 0.6980,  ..., 0.6902, 0.6902, 0.7059]],\n\n        [[0.9333, 0.9490, 0.9412,  ..., 0.9490, 0.9490, 0.9569],\n         [0.9333, 0.9490, 0.9490,  ..., 0.9490, 0.9412, 0.9490],\n         [0.9490, 0.9490, 0.9490,  ..., 0.9490, 0.9490, 0.9490],\n         ...,\n         [0.7020, 0.6941, 0.7020,  ..., 0.4039, 0.6784, 0.7020],\n         [0.6980, 0.7020, 0.7020,  ..., 0.6863, 0.6941, 0.7020],\n         [0.7255, 0.7176, 0.7098,  ..., 0.6863, 0.6863, 0.7020]]])\n"
    }
   ],
   "source": [
    "im, mask = Train_Dataset[0]\n",
    "#im = im.numpy()\n",
    "print(im)\n",
    "#mask = mask.numpy()\n",
    "#prod = np.multiply(im, mask)\n",
    "#print(prod.shape)\n",
    "#plt.imshow(im)\n",
    "#plt.imshow(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BATCH_SIZE = len(TRAIN_DATA_PATH)*0.05\n",
    "BATCH_SIZE = 10\n",
    "\n",
    "train_data_loader = data.DataLoader(dataset=Train_Dataset,batch_size=BATCH_SIZE,shuffle=True,num_workers=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Defining UNet Architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def double_conv(in_channels,out_channels):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels,out_channels,kernel_size=3,padding=0),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(in_channels,out_channels,kernel_size=3,padding=0),\n",
    "        nn.ReLU(inplace=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x124d3bb00>\nTraceback (most recent call last):\n  File \"/Users/rahulm/anaconda/envs/dl/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 926, in __del__\n    self._shutdown_workers()\n  File \"/Users/rahulm/anaconda/envs/dl/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 906, in _shutdown_workers\n    w.join()\n  File \"/Users/rahulm/anaconda/envs/dl/lib/python3.7/multiprocessing/process.py\", line 140, in join\n    res = self._popen.wait(timeout)\n  File \"/Users/rahulm/anaconda/envs/dl/lib/python3.7/multiprocessing/popen_fork.py\", line 48, in wait\n    return self.poll(os.WNOHANG if timeout == 0.0 else 0)\n  File \"/Users/rahulm/anaconda/envs/dl/lib/python3.7/multiprocessing/popen_fork.py\", line 28, in poll\n    pid, sts = os.waitpid(self.pid, flag)\nKeyboardInterrupt: \n"
    }
   ],
   "source": [
    "class UNet(nn.Module):\n",
    "\n",
    "    def __init__(self, n_class):\n",
    "        super().__init__()\n",
    "                \n",
    "        self.dconv_down1 = double_conv(3, 64)\n",
    "        self.dconv_down2 = double_conv(64, 128)\n",
    "        self.dconv_down3 = double_conv(128, 256)\n",
    "        self.dconv_down4 = double_conv(256, 512)  \n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.dconv_up3 = double_conv(512, 256)\n",
    "        self.dconv_up2 = double_conv(256, 128)\n",
    "        self.dconv_up1 = double_conv(128, 64)\n",
    "        \n",
    "        self.TConv3 = nn.ConvTranspose2d(512, 256, 2, stride=2)\n",
    "        self.TConv2 = nn.ConvTranspose2d(256, 128, 2, stride=2)\n",
    "        self.TConv1 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
    "        \n",
    "        self.conv_last = nn.Conv2d(64, n_class, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        conv1 = self.dconv_down1(x)\n",
    "        x = self.maxpool(conv1)\n",
    "        \n",
    "        conv2 = self.dconv_down2(x)\n",
    "        x = self.maxpool(conv2)\n",
    "        \n",
    "        conv3 = self.dconv_down3(x)\n",
    "        x = self.maxpool(conv3)\n",
    "        \n",
    "        x = self.dconv_down4(x)\n",
    "        \n",
    "        x = self.TConv3(x)\n",
    "        x = torch.cat([x, conv3], dim=1)\n",
    "\n",
    "        x = self.dconv_up3(x)\n",
    "        x = self.TConv2(x)\n",
    "        x = torch.cat([x, conv2], dim=1)\n",
    "\n",
    "        x = self.dconv_up2(x)\n",
    "        x = self.TConv1(x)\n",
    "        x = torch.cat([x, conv1], dim=1)\n",
    "\n",
    "        x = self.dconv_up1(x)\n",
    "        out = self.conv_last(x)\n",
    "        out = F.sigmoid(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(n_class=1)\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-5)\n",
    "criterion = nn.BCELoss()\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 3\n",
    "running_loss = 0.0 \n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    loss = 0.0 \n",
    "    for i, (x,y) in enumerate(train_data_loader):\n",
    "        print(i)\n",
    "        X = Variable(x)\n",
    "        Y = Variable(y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X)\n",
    "\n",
    "        loss = criterion(ouput,Y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        print(\"loss for epoch \" + str(epoch) + \":  \" + str(running_loss))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### "
   ]
  }
 ]
}